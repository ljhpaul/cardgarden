{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "49b2ce22-9196-4dab-94d6-f89ab1e77d12",
   "metadata": {},
   "source": [
    "# DQN 값 저장 시작"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a832d3a-d429-432a-8e31-0d9a6d309c7a",
   "metadata": {},
   "source": [
    "## 시작전 DQN에 관하여\n",
    "#### DQN 설명\n",
    "##### 1. DQN은 Deep-Q-Network 줄임말이다. 이는 '강화학습'이라 불리우며 '보상을 최대화하도록 스스로 학습하는 알고리즘이라 불리운다.\n",
    "##### 2. Q-Learning이라는 전통적인 강화학습 방법을 딥러닝으로 확장한 것이라 볼 수 있다.\n",
    "##### 3. Q에 관하여\n",
    "###### -여기서 Q값은 이 상태에서 하나의 행동을 진행하면 그에 대한 기대 보상이라 볼 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2453621-12d7-4226-bce9-8c6b31a91346",
   "metadata": {},
   "source": [
    "### cosine 유사도와 다른 유사도\n",
    "##### 1. 코사인 유사도: 각도의 유사성/ -1~1/ 텍스트, 백터/ 문서...\n",
    "##### 2. 유클리드 거리: 절대거리(크기포함) 0~무한대/ 좌표/실수값 데이터 좌표거리 측정\n",
    "##### 3. 자카드 유사도: 집합의 교칩합 합집합/0~1 이진,집합 데이터/ 태그,키워드"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0658c205-c506-4647-8dea-ef49329a09b2",
   "metadata": {},
   "source": [
    "### 코사인 유사도 비교\n",
    "#### 코사인 유사도는 데이터가 얼마나 비슷한지 수치화한 데이터인데 강화학습은 해당 선택에 관하여 보상(좋아요 비중, 선택 비중 등)을 학습하여 보다 적절한 결과를 출력\n",
    "##### 1.코사인유사도: 두 데이터의 각도가 얼마나 비슷한지\n",
    "##### 2.강화학습 행동을 실행할때마다 보상을 얼마나 받아갈지"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "110b4e00-419f-4577-a770-95d32d9c1a28",
   "metadata": {},
   "source": [
    "### 필수 패키지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b0f6895-4b69-45cd-9651-33ff07a490e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "import time\n",
    "import itertools\n",
    "import pymysql\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "778d9ace-5f18-4ac6-a8b2-ca598762f00c",
   "metadata": {},
   "source": [
    "### 코사인 유사도\n",
    "#### 해당 과정을 통해 유사한 action 즉 DQN에서 행동에 관해 선택하는 기준을 제공\n",
    "##### 현재 유사한 혜택을 가진 카드 20개를 선택해서 action을 정하도록함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8be7d93-4ea2-4915-a93c-4fe590f4c703",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(vec1, vec2):\n",
    "    v1 = np.array(vec1)\n",
    "    v2 = np.array(vec2)\n",
    "    return np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2) + 1e-8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c552ed8-2505-46be-9bb4-842901a8417d",
   "metadata": {},
   "source": [
    "### 데이터를 DATABASE에서 불러와 min-max 정규화 진행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ce2482-a984-4b2b-a72d-8a9efaba6c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dic = {}\n",
    "conn = pymysql.connect(\n",
    "    host='localhost',\n",
    "    user='cardgarden',\n",
    "    password='1234',\n",
    "    database='cardgarden',\n",
    "    charset='utf8mb4',\n",
    "    cursorclass=pymysql.cursors.DictCursor\n",
    ")\n",
    "\n",
    "with conn.cursor() as cursor:\n",
    "    cursor.execute(\"SELECT card_id, card_like FROM Card\")\n",
    "    rows = cursor.fetchall()\n",
    "    likes = [row['card_like'] for row in rows]\n",
    "    min_like = min(likes)\n",
    "    max_like = max(likes)\n",
    "    if max_like == min_like:\n",
    "        for row in rows:\n",
    "            dic[row['card_id']] = 0.5\n",
    "    else:\n",
    "        for row in rows:\n",
    "            dic[row['card_id']] = (row['card_like'] - min_like) / (max_like - min_like)\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03a0d463-e4bb-4446-b631-a608a81f73da",
   "metadata": {},
   "source": [
    "### 카드 혜택 데이터 백터화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93909207-7464-44be-82b6-f375852001bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_key2 = ['모든가맹점','모빌리티','대중교통','통신','생활','쇼핑','외식/카페','뷰티/피트니스','금융/포인트','병원/약국','문화/취미','숙박/항공']\n",
    "conn = pymysql.connect(\n",
    "    host='localhost',\n",
    "    user='cardgarden',\n",
    "    password='1234',\n",
    "    db='test',\n",
    "    charset='utf8mb4',\n",
    "    cursorclass=pymysql.cursors.DictCursor\n",
    ")\n",
    "try:\n",
    "    with conn.cursor() as cursor:\n",
    "        sql = \"\"\"\n",
    "        SELECT cbd.card_id,bc.benefitcategory_id\n",
    "        FROM CardBenefitDetail cbd\n",
    "            INNER JOIN BenefitDetail bd ON cbd.benefitdetail_id = bd.benefitdetail_id\n",
    "            INNER JOIN BenefitCategory bc ON bd.benefitcategory_id = bc.benefitcategory_id;\n",
    "        \"\"\"\n",
    "        cursor.execute(sql)\n",
    "        benefitDetail = cursor.fetchall()\n",
    "        cardId_dic = list({row[\"card_id\"] for row in benefitDetail})\n",
    "finally:\n",
    "    conn.close()\n",
    "\n",
    "rows = []\n",
    "for card_id in cardId_dic:\n",
    "    arr = [card_id] + [0] * len(arr_key2)\n",
    "    for item in benefitDetail:\n",
    "        if item[\"card_id\"] == card_id:\n",
    "            benefit_index = item[\"benefitcategory_id\"] - 1\n",
    "            if 0 <= benefit_index < len(arr_key2):\n",
    "                arr[benefit_index + 1] = 1\n",
    "    rows.append(arr)\n",
    "df_card = pd.DataFrame(rows, columns=[\"카드번호\"] + arr_key2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a26d86e6-4bce-410d-88a2-86d371810ac6",
   "metadata": {},
   "source": [
    "### 고객 소비 데이터 벡터화(금액) 및 reward/action 매핑"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3767412-cd9f-4e26-aa26-250d00b3c160",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sql DataBase 값 불러온 후 DataFrame 형태로 저장\n",
    "engine = create_engine(\"mysql+pymysql://cardgarden:1234@localhost/cardgarden?charset=utf8mb4\")\n",
    "sql_pattern = \"SELECT pattern_id, user_id FROM UserConsumptionPattern \"\n",
    "sql_detail = \"SELECT pattern_id, benefitcategory_id, amount FROM UserConsumptionPatternDetail\"\n",
    "sql_like = \"SELECT card_id, user_id FROM LikeCard\"\n",
    "df_pattern_all = pd.read_sql(sql_pattern, engine)\n",
    "df_detail = pd.read_sql(sql_detail, engine)\n",
    "df_like = pd.read_sql(sql_like,engine)\n",
    "engine.dispose()\n",
    "# 카테고리값 매칭\n",
    "categories = arr_key2\n",
    "# 카테고리 숫자 매핑 SQL에 값을 저장하였다면 해당 과정은 SQL에서 불러온 후 매핑 진행\n",
    "category_id_map = {cat: i+1 for i, cat in enumerate(categories)}\n",
    "id_to_category = {v: k for k, v in category_id_map.items()}\n",
    "\n",
    "\n",
    "df_detail[\"benefitcategory_name\"] = df_detail[\"benefitcategory_id\"].map(id_to_category)\n",
    "# 새로운 DataFarme 생성\n",
    "df_wide = pd.DataFrame(columns=[\"고객번호\"] + arr_key2)\n",
    "for pid in df_detail[\"pattern_id\"].unique():\n",
    "    user_id = df_pattern_all[df_pattern_all[\"pattern_id\"] == pid][\"user_id\"].values[0]\n",
    "    # 임시 저장 List 생성\n",
    "    arr1 = [user_id] + [0] * len(arr_key2)\n",
    "    subset = df_detail[df_detail[\"pattern_id\"] == pid]\n",
    "    for _, row in subset.iterrows():\n",
    "        bid = row[\"benefitcategory_id\"]\n",
    "        # amount값이 있으면 해당 값을 설정 나머지는 0의 값 부여\n",
    "        amount = row.get(\"amount\", 0)\n",
    "        if bid in id_to_category:\n",
    "            cat_name = id_to_category[bid]\n",
    "            idx = arr_key2.index(cat_name)\n",
    "            arr1[idx + 1] = amount  # 금액 반영\n",
    "    df_wide.loc[len(df_wide)] = arr1\n",
    "\n",
    "\n",
    "# 해당 값 min-max 정규화 진행\n",
    "for cat in arr_key2:\n",
    "    max_amt = df_wide[cat].max()\n",
    "    min_amt = df_wide[cat].min()\n",
    "    if max_amt > min_amt:\n",
    "        df_wide[cat] = (df_wide[cat] - min_amt) / (max_amt - min_amt)\n",
    "    elif max_amt > 0:  # 전부 같은 값이지만 0이 아닌 경우\n",
    "        df_wide[cat] = 1.0\n",
    "    # 모두 0이면 그냥 0\n",
    "# 유저별 좋아요 한 카드 목록\n",
    "like_rows = {}\n",
    "for i in range(len(df_like)):\n",
    "    if df_like['user_id'][i] not in like_rows:\n",
    "        like_rows[df_like['user_id'][i]] = []\n",
    "    like_rows[df_like['user_id'][i]].append(df_like['card_id'][i])\n",
    "\n",
    "df_sorted_desc = df_wide.sort_values(by='고객번호', ascending=True).reset_index(drop=True)\n",
    "card_data = {row[0]: row[1:] for row in rows}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eb13bdf-51a9-43b3-9f9b-e857b513568e",
   "metadata": {},
   "source": [
    "### 카드 action의 값을 설정하기 위한 유사한 혜택을 가진 카드 설정\n",
    "#### 1. 해당 데이터는 고객이 소비패턴을 입력하고 카드를 선택한다면 해당 데이터를\n",
    "#### 2. 소비패턴에 카드의 이름도 입력한다면 해당 카드 정보를"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe7137a-5f1f-435a-bf47-8fa4424c7bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "TOP_N = 20\n",
    "\n",
    "action_list = []\n",
    "for i in range(len(df_sorted_desc)):\n",
    "    state = [df_sorted_desc[c][i] for c in arr_key2]\n",
    "    similarities = []\n",
    "    for card_id, card_vec in card_data.items():\n",
    "        sim = cosine_similarity(state, card_vec)\n",
    "        similarities.append((card_id, sim))\n",
    "    similarities.sort(key=lambda x: x[1], reverse=True)\n",
    "    n = min(TOP_N, len(similarities))\n",
    "    top_n_cards = similarities[:n]\n",
    "    chosen_card = random.choice([cid for cid, _ in top_n_cards])\n",
    "    action_list.append(chosen_card)\n",
    "df_sorted_desc['action'] = action_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1987e34a-d429-4ee1-8d9b-c19c211ed3b7",
   "metadata": {},
   "source": [
    "### action 값 채우기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4333acc6-ade3-4593-923c-68ceb638cdad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 좋아요 한 카드와 매핑을 위한 준비\n",
    "for i, val in enumerate(df_sorted_desc['action']):\n",
    "    # action 값이 비어있는(없거나 NaN, None, '') 데이터만 보정\n",
    "    if pd.isna(val) or val is None or val == '':\n",
    "        user_id = df_sorted_desc.loc[i, \"고객번호\"]  # 현재 행의 user_id 추출\n",
    "        possible_values = []\n",
    "        # 해당 user가 좋아요 한 카드가 있다면 후보로 설정\n",
    "        if user_id in like_rows and like_rows[user_id]:\n",
    "            possible_values = like_rows[user_id]\n",
    "        else:\n",
    "            # 없다면 모든 유저의 좋아요 카드 id를 후보로 설정 (랜덤 추출을 위함)\n",
    "            possible_values = [item for sublist in like_rows.values() for item in sublist]\n",
    "        if possible_values:\n",
    "            # 후보 카드가 있으면 랜덤으로 하나 선택해서 action에 할당\n",
    "            df_sorted_desc.at[i, 'action'] = random.choice(possible_values)\n",
    "        else:\n",
    "            # 후보도 없다면 action에 None 기록\n",
    "            df_sorted_desc.at[i, 'action'] = None\n",
    "\n",
    "# 좋아요 한 카드를 본격적인 매칭 (reward 값 할당)\n",
    "like_list = []\n",
    "for i in range(len(df_sorted_desc)):\n",
    "    act = df_sorted_desc['action'][i]  # action(카드 id) 추출\n",
    "    # 카드별 reward 점수(dic에 있으면 사용, 없으면 0.5의 기본값)\n",
    "    like_list.append(dic[act] if act in dic else 0.5)\n",
    "df_sorted_desc['reward'] = like_list  # reward 컬럼 추가\n",
    "\n",
    "# 카드데이터 리스트 추출하여 ID값 설정\n",
    "card_ids = [df_card[\"카드번호\"].iloc[i] for i in range(len(df_card))]  # 전체 카드 id 리스트\n",
    "action_size = len(card_ids)  # 전체 카드 개수(action space size)\n",
    "card_data = {row[0]: row[1:] for row in rows}  # 카드 id별 벡터(또는 feature) dict\n",
    "\n",
    "# 학습 전 본격적인 training_data 설정\n",
    "training_data = []\n",
    "for i in range(len(df_sorted_desc)):\n",
    "    # 각 샘플의 상태(state): 카테고리별 소비 패턴 벡터\n",
    "    state = [df_sorted_desc[c][i] for c in arr_key2]\n",
    "    action = df_sorted_desc['action'][i]  # 추천된(또는 보정된) 카드 id\n",
    "    reward = df_sorted_desc['reward'][i]  # reward 값\n",
    "    training_data.append({\n",
    "        \"user_id\": df_sorted_desc['고객번호'][i],  # 고객번호\n",
    "        \"state\": state,                           # 소비 패턴(입력 특성 벡터)\n",
    "        \"action\": action,                         # 추천/선택된 카드 id\n",
    "        \"reward\": reward                          # reward 값(좋아요 등)\n",
    "    })\n",
    "\n",
    "# 실제 카드 id 집합 (유효 카드 id만 필터링용)\n",
    "valid_card_ids = set(card_data.keys())\n",
    "\n",
    "\n",
    "# 이 아래서 실제 학습에 쓸 데이터만 골라낼 리스트(아직 비어있음)\n",
    "filtered_training_data = []\n",
    "\n",
    "# 각 샘플(state-action 쌍)에 대해 추가 보정된 reward 계산\n",
    "for i, sample in enumerate(training_data):\n",
    "    state = np.array(sample[\"state\"])\n",
    "    action_key = int(sample[\"action\"])\n",
    "    # 카드 정보 없는 경우 스킵\n",
    "    if action_key not in card_data:\n",
    "        continue\n",
    "    card_vec = np.array(card_data[action_key])\n",
    "    sim = cosine_similarity(state, card_vec)\n",
    "\n",
    "    # 💡 sim(유사도)이 0.05 이하라면 강하게 패널티 (거의 매칭이 안된 케이스)\n",
    "    if sim <= 0.05:\n",
    "        reward = 0.01   # 아주 낮은 reward (실패 케이스)\n",
    "    else:\n",
    "        user_id = sample[\"user_id\"]\n",
    "        user_likes = like_rows.get(user_id, [])\n",
    "        if user_likes:\n",
    "            # 유저가 좋아요한 카드들과 현재 action 카드와의 유사도 평균\n",
    "            like_sims = [cosine_similarity(card_vec, card_data[like_id]) for like_id in user_likes if like_id in card_data]\n",
    "            like_sim_score = np.mean(like_sims) if like_sims else 0\n",
    "        else:\n",
    "            like_sim_score = 0\n",
    "        # reward 계산 (좋아요 점수, 코사인 유사도, 좋아요 카드와의 유사도 가중합)\n",
    "        reward = 0.4 * dic.get(action_key, 0.5) + 0.4 * sim + 0.2 * like_sim_score\n",
    "    training_data[i][\"reward\"] = reward  # reward 값 갱신\n",
    "\n",
    "# 전체 action(카드id) 모음 → action 인덱스 부여용\n",
    "all_actions = set(int(sample[\"action\"]) for sample in training_data if sample[\"action\"] is not None)\n",
    "card_id_to_index = {action: idx for idx, action in enumerate(sorted(all_actions))}\n",
    "state_size = 12   # 입력 벡터(소비 카테고리) 차원 수"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e571ada-8065-4c47-9a4b-77851571dee6",
   "metadata": {},
   "source": [
    "### 학습 시작"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77317268-6bba-49dc-a22a-7d3cabb5e0a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQN(nn.Module):\n",
    "    def __init__(self, state_size, action_size):\n",
    "        super(DQN, self).__init__()\n",
    "        # 3층 fully-connected(완전연결) 신경망\n",
    "        self.fc1 = nn.Linear(state_size, 32)\n",
    "        self.fc2 = nn.Linear(32, 32)\n",
    "        self.fc3 = nn.Linear(32, action_size)\n",
    "    def forward(self, x):\n",
    "        # 순전파: relu → relu → (최종 layer는 선형)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        return self.fc3(x)\n",
    "\n",
    "model = DQN(state_size, action_size)    # DQN 네트워크 인스턴스 생성\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)  # Adam 옵티마이저\n",
    "criterion = nn.MSELoss()    # 손실 함수: 평균제곱오차(MSE)\n",
    "patience = 30               # 조기 종료를 위한 patience 설정\n",
    "best_loss = float('inf')\n",
    "trigger_times = 0\n",
    "\n",
    "# DQN 학습 루프 (최대 200 epoch)\n",
    "for epoch in range(200):\n",
    "    total_loss = 0\n",
    "    for sample in training_data:\n",
    "        state = torch.tensor(sample[\"state\"], dtype=torch.float32)     # 입력 state 벡터\n",
    "        action_value = sample[\"action\"]                                # 실제 action(card id)\n",
    "        try:\n",
    "            action = card_id_to_index[int(action_value)]               # action 인덱스\n",
    "        except KeyError:\n",
    "            print(f\"존재하지 않는 키입니다: {action_value}\")           # mapping 안 된 경우 건너뜀\n",
    "            continue\n",
    "        reward = sample[\"reward\"]                                      # reward 값\n",
    "        q_values = model(state)                                        # Q값 추정 (모든 action에 대해)\n",
    "        target = q_values.clone().detach()                             # 타겟 Q값: 복사본\n",
    "        target[action] = reward                                        # 실제 action의 Q만 reward로 대체\n",
    "        loss = criterion(q_values, target)                             # 손실 계산\n",
    "        optimizer.zero_grad()                                          # 기울기 0 초기화\n",
    "        loss.backward()                                                # 역전파\n",
    "        optimizer.step()                                               # 가중치 업데이트\n",
    "        total_loss += loss.item()\n",
    "    if epoch % 20 == 0:\n",
    "        print(f\"Epoch {epoch}, Loss: {total_loss:.4f}\")                # 20 epoch마다 손실 출력\n",
    "    if total_loss < best_loss:                                         # 조기종료 조건 체크\n",
    "        best_loss = total_loss\n",
    "        trigger_times = 0\n",
    "    else:\n",
    "        trigger_times += 1\n",
    "        if trigger_times >= patience:\n",
    "            print(f\"🛑 조기 종료 at epoch {epoch} (Loss 미개선 {patience}회)\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34884105-2c7b-4597-af83-780a0f29f9de",
   "metadata": {},
   "source": [
    "### 결과 값 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb07e1e-e786-4d66-bc09-e2d9b70fc72d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모든 (카테고리별 0/1 조합) state에 대해 Q값 테이블 생성 (이진 feature의 모든 조합)\n",
    "levels = [0.0, 1.0]\n",
    "n = 12  # 카테고리 수\n",
    "user_states = list(itertools.product(levels, repeat=n))  # 가능한 모든 상태 조합\n",
    "\n",
    "data = []\n",
    "for user_state in user_states:\n",
    "    state_tensor = torch.tensor(user_state, dtype=torch.float32)\n",
    "    q_values = model(state_tensor)\n",
    "    row = {\"user_state\": \",\".join([f\"{v:.3f}\" for v in user_state])}\n",
    "    # 각 카드 id 별 Q값 저장\n",
    "    for cid in card_id_to_index.keys():\n",
    "        row[str(cid)] = q_values[card_id_to_index[cid]].item()\n",
    "    data.append(row)\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df.to_parquet(\"/Users/isanghyeon/Documents/workspace-sts-3.9.18.RELEASE/cardgarden/python/result/q_table_continuous1.parquet\")\n",
    "print(\"✅ Q값 테이블을 Parquet 파일(q_table_continuous1.parquet)로 저장했습니다.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
