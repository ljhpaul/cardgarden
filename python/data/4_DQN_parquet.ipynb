{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "49b2ce22-9196-4dab-94d6-f89ab1e77d12",
   "metadata": {},
   "source": [
    "# DQN ê°’ ì €ì¥ ì‹œì‘"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a832d3a-d429-432a-8e31-0d9a6d309c7a",
   "metadata": {},
   "source": [
    "## ì‹œì‘ì „ DQNì— ê´€í•˜ì—¬\n",
    "#### DQN ì„¤ëª…\n",
    "##### 1. DQNì€ Deep-Q-Network ì¤„ì„ë§ì´ë‹¤. ì´ëŠ” 'ê°•í™”í•™ìŠµ'ì´ë¼ ë¶ˆë¦¬ìš°ë©° 'ë³´ìƒì„ ìµœëŒ€í™”í•˜ë„ë¡ ìŠ¤ìŠ¤ë¡œ í•™ìŠµí•˜ëŠ” ì•Œê³ ë¦¬ì¦˜ì´ë¼ ë¶ˆë¦¬ìš´ë‹¤.\n",
    "##### 2. Q-Learningì´ë¼ëŠ” ì „í†µì ì¸ ê°•í™”í•™ìŠµ ë°©ë²•ì„ ë”¥ëŸ¬ë‹ìœ¼ë¡œ í™•ì¥í•œ ê²ƒì´ë¼ ë³¼ ìˆ˜ ìˆë‹¤.\n",
    "##### 3. Qì— ê´€í•˜ì—¬\n",
    "###### -ì—¬ê¸°ì„œ Qê°’ì€ ì´ ìƒíƒœì—ì„œ í•˜ë‚˜ì˜ í–‰ë™ì„ ì§„í–‰í•˜ë©´ ê·¸ì— ëŒ€í•œ ê¸°ëŒ€ ë³´ìƒì´ë¼ ë³¼ ìˆ˜ ìˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2453621-12d7-4226-bce9-8c6b31a91346",
   "metadata": {},
   "source": [
    "### cosine ìœ ì‚¬ë„ì™€ ë‹¤ë¥¸ ìœ ì‚¬ë„\n",
    "##### 1. ì½”ì‚¬ì¸ ìœ ì‚¬ë„: ê°ë„ì˜ ìœ ì‚¬ì„±/ -1~1/ í…ìŠ¤íŠ¸, ë°±í„°/ ë¬¸ì„œ...\n",
    "##### 2. ìœ í´ë¦¬ë“œ ê±°ë¦¬: ì ˆëŒ€ê±°ë¦¬(í¬ê¸°í¬í•¨) 0~ë¬´í•œëŒ€/ ì¢Œí‘œ/ì‹¤ìˆ˜ê°’ ë°ì´í„° ì¢Œí‘œê±°ë¦¬ ì¸¡ì •\n",
    "##### 3. ìì¹´ë“œ ìœ ì‚¬ë„: ì§‘í•©ì˜ êµì¹©í•© í•©ì§‘í•©/0~1 ì´ì§„,ì§‘í•© ë°ì´í„°/ íƒœê·¸,í‚¤ì›Œë“œ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0658c205-c506-4647-8dea-ef49329a09b2",
   "metadata": {},
   "source": [
    "### ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ë¹„êµ\n",
    "#### ì½”ì‚¬ì¸ ìœ ì‚¬ë„ëŠ” ë°ì´í„°ê°€ ì–¼ë§ˆë‚˜ ë¹„ìŠ·í•œì§€ ìˆ˜ì¹˜í™”í•œ ë°ì´í„°ì¸ë° ê°•í™”í•™ìŠµì€ í•´ë‹¹ ì„ íƒì— ê´€í•˜ì—¬ ë³´ìƒ(ì¢‹ì•„ìš” ë¹„ì¤‘, ì„ íƒ ë¹„ì¤‘ ë“±)ì„ í•™ìŠµí•˜ì—¬ ë³´ë‹¤ ì ì ˆí•œ ê²°ê³¼ë¥¼ ì¶œë ¥\n",
    "##### 1.ì½”ì‚¬ì¸ìœ ì‚¬ë„: ë‘ ë°ì´í„°ì˜ ê°ë„ê°€ ì–¼ë§ˆë‚˜ ë¹„ìŠ·í•œì§€\n",
    "##### 2.ê°•í™”í•™ìŠµ í–‰ë™ì„ ì‹¤í–‰í• ë•Œë§ˆë‹¤ ë³´ìƒì„ ì–¼ë§ˆë‚˜ ë°›ì•„ê°ˆì§€"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "110b4e00-419f-4577-a770-95d32d9c1a28",
   "metadata": {},
   "source": [
    "### í•„ìˆ˜ íŒ¨í‚¤ì§€"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b0f6895-4b69-45cd-9651-33ff07a490e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "import time\n",
    "import itertools\n",
    "import pymysql\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "778d9ace-5f18-4ac6-a8b2-ca598762f00c",
   "metadata": {},
   "source": [
    "### ì½”ì‚¬ì¸ ìœ ì‚¬ë„\n",
    "#### í•´ë‹¹ ê³¼ì •ì„ í†µí•´ ìœ ì‚¬í•œ action ì¦‰ DQNì—ì„œ í–‰ë™ì— ê´€í•´ ì„ íƒí•˜ëŠ” ê¸°ì¤€ì„ ì œê³µ\n",
    "##### í˜„ì¬ ìœ ì‚¬í•œ í˜œíƒì„ ê°€ì§„ ì¹´ë“œ 20ê°œë¥¼ ì„ íƒí•´ì„œ actionì„ ì •í•˜ë„ë¡í•¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8be7d93-4ea2-4915-a93c-4fe590f4c703",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(vec1, vec2):\n",
    "    v1 = np.array(vec1)\n",
    "    v2 = np.array(vec2)\n",
    "    return np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2) + 1e-8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c552ed8-2505-46be-9bb4-842901a8417d",
   "metadata": {},
   "source": [
    "### ë°ì´í„°ë¥¼ DATABASEì—ì„œ ë¶ˆëŸ¬ì™€ min-max ì •ê·œí™” ì§„í–‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ce2482-a984-4b2b-a72d-8a9efaba6c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dic = {}\n",
    "conn = pymysql.connect(\n",
    "    host='localhost',\n",
    "    user='cardgarden',\n",
    "    password='1234',\n",
    "    database='cardgarden',\n",
    "    charset='utf8mb4',\n",
    "    cursorclass=pymysql.cursors.DictCursor\n",
    ")\n",
    "\n",
    "with conn.cursor() as cursor:\n",
    "    cursor.execute(\"SELECT card_id, card_like FROM Card\")\n",
    "    rows = cursor.fetchall()\n",
    "    likes = [row['card_like'] for row in rows]\n",
    "    min_like = min(likes)\n",
    "    max_like = max(likes)\n",
    "    if max_like == min_like:\n",
    "        for row in rows:\n",
    "            dic[row['card_id']] = 0.5\n",
    "    else:\n",
    "        for row in rows:\n",
    "            dic[row['card_id']] = (row['card_like'] - min_like) / (max_like - min_like)\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03a0d463-e4bb-4446-b631-a608a81f73da",
   "metadata": {},
   "source": [
    "### ì¹´ë“œ í˜œíƒ ë°ì´í„° ë°±í„°í™”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93909207-7464-44be-82b6-f375852001bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_key2 = ['ëª¨ë“ ê°€ë§¹ì ','ëª¨ë¹Œë¦¬í‹°','ëŒ€ì¤‘êµí†µ','í†µì‹ ','ìƒí™œ','ì‡¼í•‘','ì™¸ì‹/ì¹´í˜','ë·°í‹°/í”¼íŠ¸ë‹ˆìŠ¤','ê¸ˆìœµ/í¬ì¸íŠ¸','ë³‘ì›/ì•½êµ­','ë¬¸í™”/ì·¨ë¯¸','ìˆ™ë°•/í•­ê³µ']\n",
    "conn = pymysql.connect(\n",
    "    host='localhost',\n",
    "    user='cardgarden',\n",
    "    password='1234',\n",
    "    db='test',\n",
    "    charset='utf8mb4',\n",
    "    cursorclass=pymysql.cursors.DictCursor\n",
    ")\n",
    "try:\n",
    "    with conn.cursor() as cursor:\n",
    "        sql = \"\"\"\n",
    "        SELECT cbd.card_id,bc.benefitcategory_id\n",
    "        FROM CardBenefitDetail cbd\n",
    "            INNER JOIN BenefitDetail bd ON cbd.benefitdetail_id = bd.benefitdetail_id\n",
    "            INNER JOIN BenefitCategory bc ON bd.benefitcategory_id = bc.benefitcategory_id;\n",
    "        \"\"\"\n",
    "        cursor.execute(sql)\n",
    "        benefitDetail = cursor.fetchall()\n",
    "        cardId_dic = list({row[\"card_id\"] for row in benefitDetail})\n",
    "finally:\n",
    "    conn.close()\n",
    "\n",
    "rows = []\n",
    "for card_id in cardId_dic:\n",
    "    arr = [card_id] + [0] * len(arr_key2)\n",
    "    for item in benefitDetail:\n",
    "        if item[\"card_id\"] == card_id:\n",
    "            benefit_index = item[\"benefitcategory_id\"] - 1\n",
    "            if 0 <= benefit_index < len(arr_key2):\n",
    "                arr[benefit_index + 1] = 1\n",
    "    rows.append(arr)\n",
    "df_card = pd.DataFrame(rows, columns=[\"ì¹´ë“œë²ˆí˜¸\"] + arr_key2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a26d86e6-4bce-410d-88a2-86d371810ac6",
   "metadata": {},
   "source": [
    "### ê³ ê° ì†Œë¹„ ë°ì´í„° ë²¡í„°í™”(ê¸ˆì•¡) ë° reward/action ë§¤í•‘"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3767412-cd9f-4e26-aa26-250d00b3c160",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sql DataBase ê°’ ë¶ˆëŸ¬ì˜¨ í›„ DataFrame í˜•íƒœë¡œ ì €ì¥\n",
    "engine = create_engine(\"mysql+pymysql://cardgarden:1234@localhost/cardgarden?charset=utf8mb4\")\n",
    "sql_pattern = \"SELECT pattern_id, user_id FROM UserConsumptionPattern \"\n",
    "sql_detail = \"SELECT pattern_id, benefitcategory_id, amount FROM UserConsumptionPatternDetail\"\n",
    "sql_like = \"SELECT card_id, user_id FROM LikeCard\"\n",
    "df_pattern_all = pd.read_sql(sql_pattern, engine)\n",
    "df_detail = pd.read_sql(sql_detail, engine)\n",
    "df_like = pd.read_sql(sql_like,engine)\n",
    "engine.dispose()\n",
    "# ì¹´í…Œê³ ë¦¬ê°’ ë§¤ì¹­\n",
    "categories = arr_key2\n",
    "# ì¹´í…Œê³ ë¦¬ ìˆ«ì ë§¤í•‘ SQLì— ê°’ì„ ì €ì¥í•˜ì˜€ë‹¤ë©´ í•´ë‹¹ ê³¼ì •ì€ SQLì—ì„œ ë¶ˆëŸ¬ì˜¨ í›„ ë§¤í•‘ ì§„í–‰\n",
    "category_id_map = {cat: i+1 for i, cat in enumerate(categories)}\n",
    "id_to_category = {v: k for k, v in category_id_map.items()}\n",
    "\n",
    "\n",
    "df_detail[\"benefitcategory_name\"] = df_detail[\"benefitcategory_id\"].map(id_to_category)\n",
    "# ìƒˆë¡œìš´ DataFarme ìƒì„±\n",
    "df_wide = pd.DataFrame(columns=[\"ê³ ê°ë²ˆí˜¸\"] + arr_key2)\n",
    "for pid in df_detail[\"pattern_id\"].unique():\n",
    "    user_id = df_pattern_all[df_pattern_all[\"pattern_id\"] == pid][\"user_id\"].values[0]\n",
    "    # ì„ì‹œ ì €ì¥ List ìƒì„±\n",
    "    arr1 = [user_id] + [0] * len(arr_key2)\n",
    "    subset = df_detail[df_detail[\"pattern_id\"] == pid]\n",
    "    for _, row in subset.iterrows():\n",
    "        bid = row[\"benefitcategory_id\"]\n",
    "        # amountê°’ì´ ìˆìœ¼ë©´ í•´ë‹¹ ê°’ì„ ì„¤ì • ë‚˜ë¨¸ì§€ëŠ” 0ì˜ ê°’ ë¶€ì—¬\n",
    "        amount = row.get(\"amount\", 0)\n",
    "        if bid in id_to_category:\n",
    "            cat_name = id_to_category[bid]\n",
    "            idx = arr_key2.index(cat_name)\n",
    "            arr1[idx + 1] = amount  # ê¸ˆì•¡ ë°˜ì˜\n",
    "    df_wide.loc[len(df_wide)] = arr1\n",
    "\n",
    "\n",
    "# í•´ë‹¹ ê°’ min-max ì •ê·œí™” ì§„í–‰\n",
    "for cat in arr_key2:\n",
    "    max_amt = df_wide[cat].max()\n",
    "    min_amt = df_wide[cat].min()\n",
    "    if max_amt > min_amt:\n",
    "        df_wide[cat] = (df_wide[cat] - min_amt) / (max_amt - min_amt)\n",
    "    elif max_amt > 0:  # ì „ë¶€ ê°™ì€ ê°’ì´ì§€ë§Œ 0ì´ ì•„ë‹Œ ê²½ìš°\n",
    "        df_wide[cat] = 1.0\n",
    "    # ëª¨ë‘ 0ì´ë©´ ê·¸ëƒ¥ 0\n",
    "# ìœ ì €ë³„ ì¢‹ì•„ìš” í•œ ì¹´ë“œ ëª©ë¡\n",
    "like_rows = {}\n",
    "for i in range(len(df_like)):\n",
    "    if df_like['user_id'][i] not in like_rows:\n",
    "        like_rows[df_like['user_id'][i]] = []\n",
    "    like_rows[df_like['user_id'][i]].append(df_like['card_id'][i])\n",
    "\n",
    "df_sorted_desc = df_wide.sort_values(by='ê³ ê°ë²ˆí˜¸', ascending=True).reset_index(drop=True)\n",
    "card_data = {row[0]: row[1:] for row in rows}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eb13bdf-51a9-43b3-9f9b-e857b513568e",
   "metadata": {},
   "source": [
    "### ì¹´ë“œ actionì˜ ê°’ì„ ì„¤ì •í•˜ê¸° ìœ„í•œ ìœ ì‚¬í•œ í˜œíƒì„ ê°€ì§„ ì¹´ë“œ ì„¤ì •\n",
    "#### 1. í•´ë‹¹ ë°ì´í„°ëŠ” ê³ ê°ì´ ì†Œë¹„íŒ¨í„´ì„ ì…ë ¥í•˜ê³  ì¹´ë“œë¥¼ ì„ íƒí•œë‹¤ë©´ í•´ë‹¹ ë°ì´í„°ë¥¼\n",
    "#### 2. ì†Œë¹„íŒ¨í„´ì— ì¹´ë“œì˜ ì´ë¦„ë„ ì…ë ¥í•œë‹¤ë©´ í•´ë‹¹ ì¹´ë“œ ì •ë³´ë¥¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe7137a-5f1f-435a-bf47-8fa4424c7bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "TOP_N = 20\n",
    "\n",
    "action_list = []\n",
    "for i in range(len(df_sorted_desc)):\n",
    "    state = [df_sorted_desc[c][i] for c in arr_key2]\n",
    "    similarities = []\n",
    "    for card_id, card_vec in card_data.items():\n",
    "        sim = cosine_similarity(state, card_vec)\n",
    "        similarities.append((card_id, sim))\n",
    "    similarities.sort(key=lambda x: x[1], reverse=True)\n",
    "    n = min(TOP_N, len(similarities))\n",
    "    top_n_cards = similarities[:n]\n",
    "    chosen_card = random.choice([cid for cid, _ in top_n_cards])\n",
    "    action_list.append(chosen_card)\n",
    "df_sorted_desc['action'] = action_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1987e34a-d429-4ee1-8d9b-c19c211ed3b7",
   "metadata": {},
   "source": [
    "### action ê°’ ì±„ìš°ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4333acc6-ade3-4593-923c-68ceb638cdad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì¢‹ì•„ìš” í•œ ì¹´ë“œì™€ ë§¤í•‘ì„ ìœ„í•œ ì¤€ë¹„\n",
    "for i, val in enumerate(df_sorted_desc['action']):\n",
    "    # action ê°’ì´ ë¹„ì–´ìˆëŠ”(ì—†ê±°ë‚˜ NaN, None, '') ë°ì´í„°ë§Œ ë³´ì •\n",
    "    if pd.isna(val) or val is None or val == '':\n",
    "        user_id = df_sorted_desc.loc[i, \"ê³ ê°ë²ˆí˜¸\"]  # í˜„ì¬ í–‰ì˜ user_id ì¶”ì¶œ\n",
    "        possible_values = []\n",
    "        # í•´ë‹¹ userê°€ ì¢‹ì•„ìš” í•œ ì¹´ë“œê°€ ìˆë‹¤ë©´ í›„ë³´ë¡œ ì„¤ì •\n",
    "        if user_id in like_rows and like_rows[user_id]:\n",
    "            possible_values = like_rows[user_id]\n",
    "        else:\n",
    "            # ì—†ë‹¤ë©´ ëª¨ë“  ìœ ì €ì˜ ì¢‹ì•„ìš” ì¹´ë“œ idë¥¼ í›„ë³´ë¡œ ì„¤ì • (ëœë¤ ì¶”ì¶œì„ ìœ„í•¨)\n",
    "            possible_values = [item for sublist in like_rows.values() for item in sublist]\n",
    "        if possible_values:\n",
    "            # í›„ë³´ ì¹´ë“œê°€ ìˆìœ¼ë©´ ëœë¤ìœ¼ë¡œ í•˜ë‚˜ ì„ íƒí•´ì„œ actionì— í• ë‹¹\n",
    "            df_sorted_desc.at[i, 'action'] = random.choice(possible_values)\n",
    "        else:\n",
    "            # í›„ë³´ë„ ì—†ë‹¤ë©´ actionì— None ê¸°ë¡\n",
    "            df_sorted_desc.at[i, 'action'] = None\n",
    "\n",
    "# ì¢‹ì•„ìš” í•œ ì¹´ë“œë¥¼ ë³¸ê²©ì ì¸ ë§¤ì¹­ (reward ê°’ í• ë‹¹)\n",
    "like_list = []\n",
    "for i in range(len(df_sorted_desc)):\n",
    "    act = df_sorted_desc['action'][i]  # action(ì¹´ë“œ id) ì¶”ì¶œ\n",
    "    # ì¹´ë“œë³„ reward ì ìˆ˜(dicì— ìˆìœ¼ë©´ ì‚¬ìš©, ì—†ìœ¼ë©´ 0.5ì˜ ê¸°ë³¸ê°’)\n",
    "    like_list.append(dic[act] if act in dic else 0.5)\n",
    "df_sorted_desc['reward'] = like_list  # reward ì»¬ëŸ¼ ì¶”ê°€\n",
    "\n",
    "# ì¹´ë“œë°ì´í„° ë¦¬ìŠ¤íŠ¸ ì¶”ì¶œí•˜ì—¬ IDê°’ ì„¤ì •\n",
    "card_ids = [df_card[\"ì¹´ë“œë²ˆí˜¸\"].iloc[i] for i in range(len(df_card))]  # ì „ì²´ ì¹´ë“œ id ë¦¬ìŠ¤íŠ¸\n",
    "action_size = len(card_ids)  # ì „ì²´ ì¹´ë“œ ê°œìˆ˜(action space size)\n",
    "card_data = {row[0]: row[1:] for row in rows}  # ì¹´ë“œ idë³„ ë²¡í„°(ë˜ëŠ” feature) dict\n",
    "\n",
    "# í•™ìŠµ ì „ ë³¸ê²©ì ì¸ training_data ì„¤ì •\n",
    "training_data = []\n",
    "for i in range(len(df_sorted_desc)):\n",
    "    # ê° ìƒ˜í”Œì˜ ìƒíƒœ(state): ì¹´í…Œê³ ë¦¬ë³„ ì†Œë¹„ íŒ¨í„´ ë²¡í„°\n",
    "    state = [df_sorted_desc[c][i] for c in arr_key2]\n",
    "    action = df_sorted_desc['action'][i]  # ì¶”ì²œëœ(ë˜ëŠ” ë³´ì •ëœ) ì¹´ë“œ id\n",
    "    reward = df_sorted_desc['reward'][i]  # reward ê°’\n",
    "    training_data.append({\n",
    "        \"user_id\": df_sorted_desc['ê³ ê°ë²ˆí˜¸'][i],  # ê³ ê°ë²ˆí˜¸\n",
    "        \"state\": state,                           # ì†Œë¹„ íŒ¨í„´(ì…ë ¥ íŠ¹ì„± ë²¡í„°)\n",
    "        \"action\": action,                         # ì¶”ì²œ/ì„ íƒëœ ì¹´ë“œ id\n",
    "        \"reward\": reward                          # reward ê°’(ì¢‹ì•„ìš” ë“±)\n",
    "    })\n",
    "\n",
    "# ì‹¤ì œ ì¹´ë“œ id ì§‘í•© (ìœ íš¨ ì¹´ë“œ idë§Œ í•„í„°ë§ìš©)\n",
    "valid_card_ids = set(card_data.keys())\n",
    "\n",
    "\n",
    "# ì´ ì•„ë˜ì„œ ì‹¤ì œ í•™ìŠµì— ì“¸ ë°ì´í„°ë§Œ ê³¨ë¼ë‚¼ ë¦¬ìŠ¤íŠ¸(ì•„ì§ ë¹„ì–´ìˆìŒ)\n",
    "filtered_training_data = []\n",
    "\n",
    "# ê° ìƒ˜í”Œ(state-action ìŒ)ì— ëŒ€í•´ ì¶”ê°€ ë³´ì •ëœ reward ê³„ì‚°\n",
    "for i, sample in enumerate(training_data):\n",
    "    state = np.array(sample[\"state\"])\n",
    "    action_key = int(sample[\"action\"])\n",
    "    # ì¹´ë“œ ì •ë³´ ì—†ëŠ” ê²½ìš° ìŠ¤í‚µ\n",
    "    if action_key not in card_data:\n",
    "        continue\n",
    "    card_vec = np.array(card_data[action_key])\n",
    "    sim = cosine_similarity(state, card_vec)\n",
    "\n",
    "    # ğŸ’¡ sim(ìœ ì‚¬ë„)ì´ 0.05 ì´í•˜ë¼ë©´ ê°•í•˜ê²Œ íŒ¨ë„í‹° (ê±°ì˜ ë§¤ì¹­ì´ ì•ˆëœ ì¼€ì´ìŠ¤)\n",
    "    if sim <= 0.05:\n",
    "        reward = 0.01   # ì•„ì£¼ ë‚®ì€ reward (ì‹¤íŒ¨ ì¼€ì´ìŠ¤)\n",
    "    else:\n",
    "        user_id = sample[\"user_id\"]\n",
    "        user_likes = like_rows.get(user_id, [])\n",
    "        if user_likes:\n",
    "            # ìœ ì €ê°€ ì¢‹ì•„ìš”í•œ ì¹´ë“œë“¤ê³¼ í˜„ì¬ action ì¹´ë“œì™€ì˜ ìœ ì‚¬ë„ í‰ê· \n",
    "            like_sims = [cosine_similarity(card_vec, card_data[like_id]) for like_id in user_likes if like_id in card_data]\n",
    "            like_sim_score = np.mean(like_sims) if like_sims else 0\n",
    "        else:\n",
    "            like_sim_score = 0\n",
    "        # reward ê³„ì‚° (ì¢‹ì•„ìš” ì ìˆ˜, ì½”ì‚¬ì¸ ìœ ì‚¬ë„, ì¢‹ì•„ìš” ì¹´ë“œì™€ì˜ ìœ ì‚¬ë„ ê°€ì¤‘í•©)\n",
    "        reward = 0.4 * dic.get(action_key, 0.5) + 0.4 * sim + 0.2 * like_sim_score\n",
    "    training_data[i][\"reward\"] = reward  # reward ê°’ ê°±ì‹ \n",
    "\n",
    "# ì „ì²´ action(ì¹´ë“œid) ëª¨ìŒ â†’ action ì¸ë±ìŠ¤ ë¶€ì—¬ìš©\n",
    "all_actions = set(int(sample[\"action\"]) for sample in training_data if sample[\"action\"] is not None)\n",
    "card_id_to_index = {action: idx for idx, action in enumerate(sorted(all_actions))}\n",
    "state_size = 12   # ì…ë ¥ ë²¡í„°(ì†Œë¹„ ì¹´í…Œê³ ë¦¬) ì°¨ì› ìˆ˜"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e571ada-8065-4c47-9a4b-77851571dee6",
   "metadata": {},
   "source": [
    "### í•™ìŠµ ì‹œì‘"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77317268-6bba-49dc-a22a-7d3cabb5e0a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQN(nn.Module):\n",
    "    def __init__(self, state_size, action_size):\n",
    "        super(DQN, self).__init__()\n",
    "        # 3ì¸µ fully-connected(ì™„ì „ì—°ê²°) ì‹ ê²½ë§\n",
    "        self.fc1 = nn.Linear(state_size, 32)\n",
    "        self.fc2 = nn.Linear(32, 32)\n",
    "        self.fc3 = nn.Linear(32, action_size)\n",
    "    def forward(self, x):\n",
    "        # ìˆœì „íŒŒ: relu â†’ relu â†’ (ìµœì¢… layerëŠ” ì„ í˜•)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        return self.fc3(x)\n",
    "\n",
    "model = DQN(state_size, action_size)    # DQN ë„¤íŠ¸ì›Œí¬ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)  # Adam ì˜µí‹°ë§ˆì´ì €\n",
    "criterion = nn.MSELoss()    # ì†ì‹¤ í•¨ìˆ˜: í‰ê· ì œê³±ì˜¤ì°¨(MSE)\n",
    "patience = 30               # ì¡°ê¸° ì¢…ë£Œë¥¼ ìœ„í•œ patience ì„¤ì •\n",
    "best_loss = float('inf')\n",
    "trigger_times = 0\n",
    "\n",
    "# DQN í•™ìŠµ ë£¨í”„ (ìµœëŒ€ 200 epoch)\n",
    "for epoch in range(200):\n",
    "    total_loss = 0\n",
    "    for sample in training_data:\n",
    "        state = torch.tensor(sample[\"state\"], dtype=torch.float32)     # ì…ë ¥ state ë²¡í„°\n",
    "        action_value = sample[\"action\"]                                # ì‹¤ì œ action(card id)\n",
    "        try:\n",
    "            action = card_id_to_index[int(action_value)]               # action ì¸ë±ìŠ¤\n",
    "        except KeyError:\n",
    "            print(f\"ì¡´ì¬í•˜ì§€ ì•ŠëŠ” í‚¤ì…ë‹ˆë‹¤: {action_value}\")           # mapping ì•ˆ ëœ ê²½ìš° ê±´ë„ˆëœ€\n",
    "            continue\n",
    "        reward = sample[\"reward\"]                                      # reward ê°’\n",
    "        q_values = model(state)                                        # Qê°’ ì¶”ì • (ëª¨ë“  actionì— ëŒ€í•´)\n",
    "        target = q_values.clone().detach()                             # íƒ€ê²Ÿ Qê°’: ë³µì‚¬ë³¸\n",
    "        target[action] = reward                                        # ì‹¤ì œ actionì˜ Që§Œ rewardë¡œ ëŒ€ì²´\n",
    "        loss = criterion(q_values, target)                             # ì†ì‹¤ ê³„ì‚°\n",
    "        optimizer.zero_grad()                                          # ê¸°ìš¸ê¸° 0 ì´ˆê¸°í™”\n",
    "        loss.backward()                                                # ì—­ì „íŒŒ\n",
    "        optimizer.step()                                               # ê°€ì¤‘ì¹˜ ì—…ë°ì´íŠ¸\n",
    "        total_loss += loss.item()\n",
    "    if epoch % 20 == 0:\n",
    "        print(f\"Epoch {epoch}, Loss: {total_loss:.4f}\")                # 20 epochë§ˆë‹¤ ì†ì‹¤ ì¶œë ¥\n",
    "    if total_loss < best_loss:                                         # ì¡°ê¸°ì¢…ë£Œ ì¡°ê±´ ì²´í¬\n",
    "        best_loss = total_loss\n",
    "        trigger_times = 0\n",
    "    else:\n",
    "        trigger_times += 1\n",
    "        if trigger_times >= patience:\n",
    "            print(f\"ğŸ›‘ ì¡°ê¸° ì¢…ë£Œ at epoch {epoch} (Loss ë¯¸ê°œì„  {patience}íšŒ)\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34884105-2c7b-4597-af83-780a0f29f9de",
   "metadata": {},
   "source": [
    "### ê²°ê³¼ ê°’ ì €ì¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb07e1e-e786-4d66-bc09-e2d9b70fc72d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ëª¨ë“  (ì¹´í…Œê³ ë¦¬ë³„ 0/1 ì¡°í•©) stateì— ëŒ€í•´ Qê°’ í…Œì´ë¸” ìƒì„± (ì´ì§„ featureì˜ ëª¨ë“  ì¡°í•©)\n",
    "levels = [0.0, 1.0]\n",
    "n = 12  # ì¹´í…Œê³ ë¦¬ ìˆ˜\n",
    "user_states = list(itertools.product(levels, repeat=n))  # ê°€ëŠ¥í•œ ëª¨ë“  ìƒíƒœ ì¡°í•©\n",
    "\n",
    "data = []\n",
    "for user_state in user_states:\n",
    "    state_tensor = torch.tensor(user_state, dtype=torch.float32)\n",
    "    q_values = model(state_tensor)\n",
    "    row = {\"user_state\": \",\".join([f\"{v:.3f}\" for v in user_state])}\n",
    "    # ê° ì¹´ë“œ id ë³„ Qê°’ ì €ì¥\n",
    "    for cid in card_id_to_index.keys():\n",
    "        row[str(cid)] = q_values[card_id_to_index[cid]].item()\n",
    "    data.append(row)\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df.to_parquet(\"/Users/isanghyeon/Documents/workspace-sts-3.9.18.RELEASE/cardgarden/python/result/q_table_continuous1.parquet\")\n",
    "print(\"âœ… Qê°’ í…Œì´ë¸”ì„ Parquet íŒŒì¼(q_table_continuous1.parquet)ë¡œ ì €ì¥í–ˆìŠµë‹ˆë‹¤.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
