{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "215b5f6f-46a7-4c0d-b05f-a719edd64c0f",
   "metadata": {},
   "source": [
    "# DQN ê°€ê³µ 2ì°¨"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cc43de5-5926-40d8-b017-f40cf83fe00f",
   "metadata": {},
   "source": [
    "## ì½”ë“œ ì„¤ëª…\n",
    "#### 1. ì •ê·œí™” ì œê±°\n",
    "#### 2. Top-Në§Œ ì €ì¥í•˜ì—¬ íš¨ìœ¨ ìƒìŠ¹\n",
    "#### 3. ë©”ëª¨ë¦¬ ë¬¸ì œ í•´ê²°"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fa9f1a3-47e8-4cbc-b624-526a43a1b5cf",
   "metadata": {},
   "source": [
    "### í•„ìˆ˜ íŒ¨í‚¤ì§€"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c58c9ab-c94b-492a-a2e8-b6e600360d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import pymysql\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94eb7e58-1b51-4f6d-b4c9-8c1575b6b24a",
   "metadata": {},
   "source": [
    "### 1. ì½”ì‚¬ì¸ ìœ ì‚¬ë„\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53266386-d6cc-4d00-a7f2-0664aafa9d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(vec1, vec2):\n",
    "    v1 = np.array(vec1, dtype=np.float32)\n",
    "    v2 = np.array(vec2, dtype=np.float32)\n",
    "    norm = np.linalg.norm(v1) * np.linalg.norm(v2) + 1e-8\n",
    "    return float(np.dot(v1, v2) / norm) if norm > 0 else 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed02d206-f58c-42d6-9933-8b8bf77ac893",
   "metadata": {},
   "source": [
    "### 2. ì¹´ë“œ ì¢‹ì•„ìš” (ì°¸ì¡°ë§Œ, ì •ê·œí™”X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7004d37b-68bb-4168-8a1c-463bb4c0f8d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dic = {}\n",
    "conn = pymysql.connect(\n",
    "    host='localhost',\n",
    "    user='cardgarden',\n",
    "    password='1234',\n",
    "    database='cardgarden',\n",
    "    charset='utf8mb4',\n",
    "    cursorclass=pymysql.cursors.DictCursor\n",
    ")\n",
    "with conn.cursor() as cursor:\n",
    "    cursor.execute(\"SELECT card_id, card_like FROM Card\")\n",
    "    rows = cursor.fetchall()\n",
    "    for row in rows:\n",
    "        dic[row['card_id']] = row['card_like']\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aabb116a-98ca-4446-a5c1-516217b48a6c",
   "metadata": {},
   "source": [
    "### 3. ì¹´í…Œê³ ë¦¬ ì •ë³´/ë§¤í•‘\n",
    "##### í•´ë‹¹ ì •ë³´ëŠ” ê¸°ì¡´ì—ëŠ” ìˆ«ìë¡œ ë§¤í•‘ì„ ì§„í–‰í•˜ì˜€ìŒ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fe4c52d-8ffe-463f-8af1-711639fb848f",
   "metadata": {},
   "outputs": [],
   "source": [
    "category_names = [\n",
    "    'All', 'Mobility', 'PublicTransport', 'Communication', 'Living',\n",
    "    'Shopping', 'DiningCafe', 'BeautyFitness', 'FinancePoint',\n",
    "    'HospitalPharmacy', 'CultureLeisure', 'HotelAir'\n",
    "]\n",
    "kor2eng = {\n",
    "    'ëª¨ë“ ê°€ë§¹ì ':'All', 'ëª¨ë¹Œë¦¬í‹°':'Mobility', 'ëŒ€ì¤‘êµí†µ':'PublicTransport', 'í†µì‹ ':'Communication',\n",
    "    'ìƒí™œ':'Living', 'ì‡¼í•‘':'Shopping', 'ì™¸ì‹/ì¹´í˜':'DiningCafe', 'ë·°í‹°/í”¼íŠ¸ë‹ˆìŠ¤':'BeautyFitness',\n",
    "    'ê¸ˆìœµ/í¬ì¸íŠ¸':'FinancePoint', 'ë³‘ì›/ì•½êµ­':'HospitalPharmacy', 'ë¬¸í™”/ì·¨ë¯¸':'CultureLeisure', 'ìˆ™ë°•/í•­ê³µ':'HotelAir'\n",
    "}\n",
    "conn = pymysql.connect(\n",
    "    host='localhost',\n",
    "    user='cardgarden',\n",
    "    password='1234',\n",
    "    db='test',\n",
    "    charset='utf8mb4',\n",
    "    cursorclass=pymysql.cursors.DictCursor\n",
    ")\n",
    "with conn.cursor() as cursor:\n",
    "    cursor.execute(\"SELECT benefitcategory_id, benefitcategory_name FROM BenefitCategory\")\n",
    "    cat_rows = cursor.fetchall()\n",
    "    benefit_id_to_name = {row['benefitcategory_id']: kor2eng.get(row['benefitcategory_name'], None) for row in cat_rows}\n",
    "    benefit_name_to_idx = {name: idx for idx, name in enumerate(category_names)}\n",
    "    cursor.execute(\"\"\"\n",
    "        SELECT cbd.card_id, bc.benefitcategory_id\n",
    "        FROM CardBenefitDetail cbd\n",
    "        INNER JOIN BenefitDetail bd ON cbd.benefitdetail_id = bd.benefitdetail_id\n",
    "        INNER JOIN BenefitCategory bc ON bd.benefitcategory_id = bc.benefitcategory_id\n",
    "    \"\"\")\n",
    "    benefitDetail = cursor.fetchall()\n",
    "    cardId_set = {row[\"card_id\"] for row in benefitDetail}\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aab7a01-c85e-447d-b5f2-0683325a8565",
   "metadata": {},
   "source": [
    "### 4. ì¹´ë“œ í˜œíƒ ë²¡í„°í™”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39722f05-43b7-4905-9afc-814829a9cf16",
   "metadata": {},
   "outputs": [],
   "source": [
    "card_rows = []\n",
    "for card_id in cardId_set:\n",
    "    arr = [card_id] + [0] * len(category_names)\n",
    "    for item in benefitDetail:\n",
    "        if item[\"card_id\"] == card_id:\n",
    "            cat_name = benefit_id_to_name.get(item[\"benefitcategory_id\"])\n",
    "            idx = benefit_name_to_idx.get(cat_name)\n",
    "            if idx is not None:\n",
    "                arr[idx + 1] = 1\n",
    "    card_rows.append(arr)\n",
    "df_card = pd.DataFrame(card_rows, columns=[\"card_id\"] + category_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cbe4793-2f44-40e2-a570-22340625498d",
   "metadata": {},
   "source": [
    "### 5. ì†Œë¹„íŒ¨í„´ ë²¡í„°í™” (ì •ê·œí™” ì—†ì´ ê¸ˆì•¡ ë¹„ìœ¨ ê·¸ëŒ€ë¡œ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a782c56-27b2-4d4e-a9c6-5dd8c07ace03",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine(\"mysql+pymysql://cardgarden:1234@localhost/cardgarden?charset=utf8mb4\")\n",
    "sql_pattern = \"SELECT pattern_id, user_id FROM UserConsumptionPattern\"\n",
    "sql_detail = \"SELECT pattern_id, benefitcategory_id, amount FROM UserConsumptionPatternDetail\"\n",
    "df_pattern_all = pd.read_sql(sql_pattern, engine)\n",
    "df_detail = pd.read_sql(sql_detail, engine)\n",
    "engine.dispose()\n",
    "\n",
    "pattern_vectors = []\n",
    "pattern_id_list = []\n",
    "MAX_SAMPLE = 10000  # â­ ìµœëŒ€ í•™ìŠµ íŒ¨í„´ ìˆ˜ ì œí•œ\n",
    "for idx, pid in enumerate(df_detail[\"pattern_id\"].unique()):\n",
    "    if idx >= MAX_SAMPLE:\n",
    "        break\n",
    "    user_id = df_pattern_all.loc[df_pattern_all[\"pattern_id\"] == pid, \"user_id\"].values[0]\n",
    "    arr1 = [user_id] + [0.0] * len(category_names)\n",
    "    subset = df_detail[df_detail[\"pattern_id\"] == pid]\n",
    "    total = subset[\"amount\"].sum()\n",
    "    for _, row in subset.iterrows():\n",
    "        cat_name = benefit_id_to_name.get(row[\"benefitcategory_id\"])\n",
    "        idx2 = benefit_name_to_idx.get(cat_name)\n",
    "        if idx2 is not None and total > 0:\n",
    "            arr1[idx2 + 1] = float(row.get(\"amount\", 0)) / total\n",
    "    pattern_vectors.append(arr1)\n",
    "    pattern_id_list.append(pid)\n",
    "\n",
    "df_user = pd.DataFrame(pattern_vectors, columns=[\"user_id\"] + category_names)\n",
    "card_data = {int(row[0]): list(map(float, row[1:])) for row in df_card.values}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6b71751-8a16-41c9-8dea-7f627895f084",
   "metadata": {},
   "source": [
    "### 6. ì¹´í…Œê³ ë¦¬ ì¼ì¹˜ ê°œìˆ˜/ë¹„ìœ¨ ë° ìœ ì‚¬ë„ ê³„ì‚° í•¨ìˆ˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a726263-7c69-4f0b-a050-de23605c34d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_count_and_ratio(state_vec, card_vec):\n",
    "    user_active = [i for i, v in enumerate(state_vec) if v > 0]\n",
    "    card_active = [i for i, v in enumerate(card_vec) if v > 0]\n",
    "    matched = [i for i in user_active if card_vec[i] > 0]\n",
    "    match_count = len(matched)\n",
    "    match_ratio = match_count / len(user_active) if user_active else 0\n",
    "    card_coverage_ratio = match_count / len(card_active) if card_active else 0\n",
    "    return match_count, match_ratio, card_coverage_ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff42db9-c885-4088-b3b2-882606a5b7bc",
   "metadata": {},
   "source": [
    "### 7. í•™ìŠµìš© ë°ì´í„° ìƒì„± (Top-N ìœ ì‚¬ ì¹´ë“œ, ì¹´í…Œê³ ë¦¬ ì¼ì¹˜ ë°˜ì˜)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "286e8f10-7392-4498-b7ea-e140bf3be4e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "TOP_N = 10   # â­ Top-N ì¹´ë“œ\n",
    "training_data = []\n",
    "for i in range(len(df_user)):\n",
    "    state = [float(df_user[c][i]) for c in category_names]\n",
    "    similarities = []\n",
    "    for card_id, card_vec in card_data.items():\n",
    "        sim = cosine_similarity(state, card_vec)\n",
    "        similarities.append((card_id, sim))\n",
    "    similarities.sort(key=lambda x: x[1], reverse=True)\n",
    "    top_n_cards = similarities[:min(TOP_N, len(similarities))]\n",
    "    for card_id, sim in top_n_cards:\n",
    "        card_vec = card_data[card_id]\n",
    "        match_cnt, match_ratio, card_coverage_ratio = match_count_and_ratio(state, card_vec)\n",
    "        reward = (0.7 * match_ratio + 0.3 * sim) * (0.6 + 0.4 * card_coverage_ratio)\n",
    "        training_data.append({\n",
    "            \"user_id\": df_user['user_id'][i],\n",
    "            \"state\": state,\n",
    "            \"action\": card_id,\n",
    "            \"sim\": sim,\n",
    "            \"match_count\": match_cnt,\n",
    "            \"match_ratio\": match_ratio,\n",
    "            \"card_coverage_ratio\": card_coverage_ratio,\n",
    "            \"reward\": reward\n",
    "        })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad8764a9-effd-41df-a4d8-5a60444c3e13",
   "metadata": {},
   "source": [
    "### 8. DQN ëª¨ë¸ í•™ìŠµ (ì •ê·œí™” X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "316930ce-f169-45c6-82db-dd02be0e1a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_actions = sorted(set(int(sample[\"action\"]) for sample in training_data if sample[\"action\"] is not None))\n",
    "card_id_to_index = {action: idx for idx, action in enumerate(all_actions)}\n",
    "state_size = len(category_names)\n",
    "action_size = len(card_id_to_index)\n",
    "\n",
    "class DQN(nn.Module):\n",
    "    def __init__(self, state_size, action_size):\n",
    "        super(DQN, self).__init__()\n",
    "        self.fc1 = nn.Linear(state_size, 32)\n",
    "        self.fc2 = nn.Linear(32, 32)\n",
    "        self.fc3 = nn.Linear(32, action_size)\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        return self.fc3(x)\n",
    "\n",
    "model = DQN(state_size, action_size)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.MSELoss()\n",
    "EPOCHS = 40        # â­ í•™ìŠµ ì—í­ ìˆ˜\n",
    "patience = 10      # â­ ì¡°ê¸°ì¢…ë£Œ\n",
    "best_loss = float('inf')\n",
    "trigger_times = 0\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    total_loss = 0\n",
    "    for sample in training_data:\n",
    "        state = torch.tensor(sample[\"state\"], dtype=torch.float32)\n",
    "        try:\n",
    "            action = card_id_to_index[int(sample[\"action\"])]\n",
    "        except KeyError:\n",
    "            continue\n",
    "        reward = sample[\"reward\"]\n",
    "        q_values = model(state)\n",
    "        target = q_values.clone().detach()\n",
    "        target[action] = reward\n",
    "        loss = criterion(q_values, target)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    if epoch % 5 == 0:\n",
    "        print(f\"Epoch {epoch}, Loss: {total_loss:.4f}\")\n",
    "    if total_loss < best_loss:\n",
    "        best_loss = total_loss\n",
    "        trigger_times = 0\n",
    "    else:\n",
    "        trigger_times += 1\n",
    "        if trigger_times >= patience:\n",
    "            print(f\"ğŸ›‘ Early stopping at epoch {epoch}\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dd6fd38-fa91-4944-9152-c88087cb36bd",
   "metadata": {},
   "source": [
    "### 9. Qê°’ í…Œì´ë¸” ê³„ì‚° (ì‹¤ì œ ì†Œë¹„íŒ¨í„´ user_stateë§Œ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "402d47d6-c9ee-4b09-b29f-fdfe50a3e68b",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 512\n",
    "user_state_arr = np.array([ [float(df_user[c][i]) for c in category_names] for i in range(len(df_user)) ])\n",
    "q_table_rows = []\n",
    "with torch.no_grad():\n",
    "    for i in range(0, len(user_state_arr), BATCH_SIZE):\n",
    "        batch = user_state_arr[i:i+BATCH_SIZE]\n",
    "        batch_tensor = torch.tensor(batch, dtype=torch.float32)\n",
    "        q_vals = model(batch_tensor)  # (batch_size, action_size)\n",
    "        for j in range(batch.shape[0]):\n",
    "            row = {\n",
    "                \"pattern_id\": int(pattern_id_list[i+j]),  # ì‹¤ì œ ì†Œë¹„íŒ¨í„´ íŒ¨í„´ID\n",
    "                \"user_state\": \",\".join([f\"{v:.3f}\" for v in batch[j]])\n",
    "            }\n",
    "            for cid in card_id_to_index.keys():\n",
    "                row[str(cid)] = float(q_vals[j, card_id_to_index[cid]].item())\n",
    "            q_table_rows.append(row)\n",
    "df_qtable = pd.DataFrame(q_table_rows)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19647ab9-3d0b-415e-8b80-7693f7c0cb91",
   "metadata": {},
   "source": [
    "### 10. íŒŒì¼ì €ì¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a80fac-2173-477a-9ced-8e21877b0440",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = \"/Users/isanghyeon/Documents/workspace-sts-3.9.18.RELEASE/cardgarden/python/result/q_table_fast_batch_patternonly_v3.parquet\"\n",
    "df_qtable.to_parquet(save_path)\n",
    "print(\"âœ… Qê°’ í…Œì´ë¸”(ì‹¤ì œíŒ¨í„´, ë°°ì¹˜ì¶”ë¡ , ì§‘ì¤‘ë„ë°˜ì˜) ì €ì¥ ì™„ë£Œ:\", save_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
